Elika comments on https://www.overleaf.com/project/5d938d462cf8090001a6f212 manuscript, 10/15

* abstract: i love writing abstracts, so happy to take that on - just a note that Meg already did this. 
* intro: 
** 1.1 has some confusing flow, sentence fragments, etc. some points of confusion
a) rather than immediately diving into ‘north american context’ and ‘english’ i think i’d probably say something like ‘generally, canonical babbling has been linked to xyz’ …BUT that was in north american settings/english. We’re just not sure if it holds globally, that’s one of the things we’d like to find out.
b) the intro previews CBR without calling it that (which i think is good!) but it also makes it seem like .15 and 10months is claimed to be _GOD’S TRUTH_ and it’s not clear to me that Oller ever meant it that way
c) things not in intro at all: CBO (i’m on board with a ‘layperson’s way to establish whether the child’ babbles) vs. a technical definition, but perhaps an explicit aim should be to see whether those actually diverge in what they tell us?
d) gender. do we actually think there will be gender differences based o previous lit? i had no preconceived notions about that for babble; if anything i’d guess there would be no gender diffs, since my read is that those emerge at the lexical level. 

** 1.2: first sentence mentions gaps but i’m not sure which gaps. also maybe describe lena (modal use case) before special case (audio+pics)—some flow/fragments here too.

** 1.3. : questions 1:3 do not seems to come clearly from either claims or gaps highlighted by intro (and gender especially seems to come out of nowhere)

METHODS
* where did those mat ed #s come from? either weird rendering or wrong info (512?) should pull from table of participant info on our osf and make any conversion from original coding clear
** 2.3: are we sure we had 100 utt’s from each of the 52 kids? i thought for tsi and yeli maybe it was actually way more than 100? i could be wrong
** 2.4: info about the clip making is preprocessing not annotation procedure
* should say something about LENA mandating CHN length which affected corpus A-C but not D-F or whatever
* should clarify that e.g. a clip of 1400ms turned into 400+400+400+200
** asterisk in table 2 doesn’t go anywhere
* i’d add direct links to qualtrics, osf, ihearuplay etc
* i think we need some sort of summary table of # of annotators, # of unique clips they each did on average, and probably just a footnote of the annotators who got the same clip twice, since i’mg guessing that happened super super rarely

RESULTS
* would be good to start with a clearly laid out analysis plan
%%%- DONE

* i think no_answer should be collapsed with junk or just filtered out in the first place and never analyzed. I also tbh don’t understand how that category can exist at all if the task was done being annotated? 
%%%- I don't understand either. Seems like a programming error from the task setup. Overall not a big deal given the small n, but just figured I should mention it to be maximally transparent. 

* it’s a little confusing how we go from daylong -> extracted CHI utterances -> short clips -> annotated clips with a majority answer. some sort of flowchart fig would help and help square away terminology 
%%%- Good idea, I thought something similar to what you all did in your Dev Sci paper last year would be good. Amanda's going to do this. 

** 0.1: i guess you’re differentiating 100% agreement vs. majority-but-not-100% agreement? this part’s confusing. how were clips with 26 ratings (!) handled in this scheme? i might ONLY worry about majority agreement clips for simplicity? 
%%%- I now made this clearer and state that we do not differentiate between 100% agreement and majority agreement clips. Let me know if it's still confusing. 


* generally speaking, i wouldn’t put in text stuff that’s in tables/figures, so no need to step through the % and N of canonical in each corpus (para 4), but i would put n AND % in table 1 
%%%- Let's talk this over with the group. In principle, I'm fine to remove this paragraph. 


* also again: i’d take out no_answer altogether here, it’s contributing nothing to the table 
%%%- Removed. 



* fig2: i find it confusing that some bars are more than one kid. in those cases could the kids be stacked with a black outline within the 
blue and pink showing each one or something? 
%%%- I tried that but some of the n are really low for some age groups (e.g. 0;3) making it hard to read when I divide the column. Since this isn't the most informative plot, though it is still interesting to see the relationship between canonical and noncanonical just by age, independent of corpus, maybe I should move it to the appendix?
i’d also put each x-tick. 
%%%- Adding a tick for each point on the x-axis made it very, very difficult to read the axis (even if I change the direction, size, and boldness of each tick label)



** .2: didn’t we discuss lots of ways that apparently ppl calc CBR? we should mention/justify this somewhere
%%%- will be mentioned in the previous lit. 

* i do NOT think we should collapse over kids within an age bin ever; not sure why we’d want to?
%%%- So I moved the one table and figure where I collapsed into age bins into the appendices now. I actually do think this analysis is interesting, to look at CBR growth just by age. But I agree that it's confusing to sometimes present indivdual data points for kids and sometimes, as in the first histogram, to not do so. 

* sorry but i really don’t understand the age in months vs. days distinction made throughout: i think to most readers 360 days = 11.8 months, but i think the idea here is that 360 days would actually be the 11 month ‘bin’? not sure why we need this kind of binning?
%%%- I primarily used age_in_days to avoid having to artificially visualize data by jittering overlapping points in the main CBR*age*corpus plot. But I included both age_in_days and age_in_months because age_in_months is obviously more intuitive. The only time that age_in_days comes up is for this plot and the lm/correlation I report for it. I also report the linear model results using the age_in_months variable. If using days and months still seems confusing/unncessary, let me know. I can remove it but the plot will be much harder to read (esp if I add confidence intervals, which I haven't yet). 

* para 4: i’m not sure i’d include this info: seem like somewhat arbitrary agespans. maybe just <10mo and >10 mo? 
%%%- I didn't do all children over 10mo because that spans all the way up to 36mo. But I changed the age ranges and I think the choice of ranges should be more justified now. Lmk what you think. 

* I think i’d also generally avoid going into detail about outliers in text, but maybe that’s my personal preference, both here and in the last para of .2 and in .3, it seems a little too detailed without a ready generalization/takehome to leave readers with
%%%- Part about outliers removed. 

* i’m also worried about using a N cutoff for CBO without taking into account how many clips there were; getting 10/500 != getting 10/69
%%%-We now decided to remove the artbitrary n=10 cutoff. Instead I do a binary plot of which kids have reached .15 and which haven't. 

* generally, it looks like the CBO and CBR results are essentially identical, no? do we actually need both sets of results in the paper vs. suppmatt? if we want both then a much clearer “just as we saw in CBR…” would be very helpful
%%%-Yes, CBO has mostly been removed now. 

* fig 3/4: i’d do 1 dot per kid no collapsing by any kind of bracket or sizing of dots; the line fit doesn’t take that into account properly for instance, and i think it’s confusing
%%%-Each point represents one child and size now refers to the number of clips that went into calculating that child's CBR. 

* fig 5: why only 4 corpora? it looks like this is bc of only a tiny amount of relevant data for warlaumont, but not sure why cychosz was removed? in any even this should be clearly stated somewhere, sorry if i missed it
%%%-Only four corpora because we're looking at a cross-sectional sample within each corpus. This is now mentioned more explicitly in the text. 


* fig 5: i’d do smaller/hollow dots, and a free x axis
%%%-Made dots smaller and fainter to see overlap better. Isn't a free scale kind of misleading? Since some corpora (Seedlings) have smaller age range than others (Tseltal, Yeli)? Or would you suggest that I free the scale but explicitly mention in the caption that the x-axis range differs by corpus?


** .3: header says ‘by corpus’ sentence one says ‘by language’ which do you mean? i wouldn’t put the correlation data in text, i’d just make it one table with the CBO and CBR (if we keep both in main text) Rs, Ns, CIs, age-ranges, and Pvals so that text can talk about take-home not details
%%%-changed to say corpus throughout instead of language

* insignificant != not statistically significant.
%%%-changed

** .4 
* not sure we need the results by gender at all—and not sure what we should be concluding. the correlations of m vs. female have overlapping CIs, and i’m not sure the potential age concern is an age concern given the wide SDs on each genders ages
%%%-We did decide in the meeting to keep the analyses by gender. I now just mention that age range *could* be a concern between males and females to help explain why we didn't replicate the finding that CBR shows stronger growth in female children than male. 

*general point: i’m a big fan of a tiny bit of interp at the end of each results para/section to help readers sift through and tie results to the initially framed questions from intro
%%%-Have now added a quick blurb at the end of each major section that ties it back into the research questions. 
